{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atomwalk12/anaconda3/envs/dev/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/atomwalk12/Dropbox (Old)/notes/vision/project/BeyondVisionQA/VisualQA/docs/transformers/transformers/src/transformers/tokenization_utils_base.py:1602: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"./docs/transformers/transformers/src\")\n",
    "\n",
    "from transformers import Blip2Processor\n",
    "from lib.types import HFRepos, VQAParameters\n",
    "from lib.daquar.daquar_generation import DaquarGeneration\n",
    "from lib.easy_vqa.easyvqa_generation import EasyVQAGeneration\n",
    "from lib.visualization import calculate_label_frequency\n",
    "from lib.visualization import calculate_cardinality_and_density, create_label_frequency_boxplot\n",
    "from lib.types import Suffix\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Load dependencies\n",
    "processor = Blip2Processor.from_pretrained(HFRepos.BLIP2_OPT)\n",
    "\n",
    "EASY_VQA_COMBINED = \"easyvqa_images/easyvqa_combined\"\n",
    "EASY_VQA_FILTERED = \"easyvqa_images/easyvqa_filtered\"\n",
    "DAQUAR_COMBINED = \"daquar_images/daquar_combined\"\n",
    "DAQUAR_FILTERED = \"daquar_images/daquar_filtered\"\n",
    "DAQUAR_PROPORTIONAL = \"daquar_images/daquar_proportional\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Analysis\n",
    "## Combined Easy-VQA dataset\n",
    "\n",
    "Intuition around the boxplot:\n",
    "\n",
    "1. **Outliers**: the items with over 17000 labels are likely to cause issues.\n",
    "2. **Box and Whiskers**: the boxplot presents the interquartile range (IQR), and it is located near the bottom of the frequency axis. This indicates that the middle 50% of the label frequencies are clustered near the lower end of the distribution.\n",
    "\n",
    "Potential issues:\n",
    "\n",
    "1. **Imbalanced Training**: The model may become biased towards frequently occurring labels, leading to poor generalization and underperformance on less frequent labels.\n",
    "2. **Overfitting to Common Labels**: The model might overfit to the highly frequent outlier labels, impairing its ability to accurately predict or generate responses for less common labels.\n",
    "3. **Difficulty in Learning Rare Labels**: Underrepresented labels may not be learned effectively, causing the model to struggle with questions requiring these labels during inference.\n",
    "4. **Reduced Model Robustness**: The model's robustness may be compromised, resulting in poor performance on unseen data, particularly if it contains more instances of less frequent labels.\n",
    "\n",
    "\n",
    "### Box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lib.easy_vqa.easyvqa_base:Read combined dataset, length: 48248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: 813.0\n",
      "Q2: 826.0\n",
      "Q3: 2105.0\n",
      "IQR: 1292.0\n",
      "Lower Whisker: -1125.0\n",
      "Upper Whisker: 4043.0\n",
      "Number of unique labels: 13\n",
      "Mean frequency: 3711.38\n",
      "Median frequency: 826.00\n",
      "Number of outliers: 2\n",
      "Total number of items: 48248\n"
     ]
    }
   ],
   "source": [
    "args = VQAParameters(Suffix.All, recompute=True) # using combined dataset\n",
    "args.processor = processor\n",
    "dataset = EasyVQAGeneration(args)\n",
    "create_label_frequency_boxplot(dataset, path=f\"{EASY_VQA_COMBINED}_all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Distribution Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lib.dataset_base:Loaded 48248 items from /home/atomwalk12/Dropbox (Old)/notes/vision/project/BeyondVisionQA/VisualQA/data/easy-vqa/generation/all.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of items:\n",
      " 48248\n",
      "Top 10 most frequent labels:\n",
      "            Frequency\n",
      "yes            17840\n",
      "no             17703\n",
      "rectangle       2151\n",
      "circle          2105\n",
      "triangle        2003\n",
      "teal             841\n",
      "green            826\n",
      "gray             822\n",
      "black            817\n",
      "blue             813\n",
      "Top 10 least frequent labels:\n",
      "           Frequency\n",
      "circle         2105\n",
      "triangle       2003\n",
      "teal            841\n",
      "green           826\n",
      "gray            822\n",
      "black           817\n",
      "blue            813\n",
      "yellow          808\n",
      "red             761\n",
      "brown           758\n"
     ]
    }
   ],
   "source": [
    "args = VQAParameters(\"all\")\n",
    "args.processor = processor\n",
    "dataset = EasyVQAGeneration(args)\n",
    "calculate_label_frequency(dataset, path=f\"{EASY_VQA_COMBINED}_all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Results\n",
    "The idea is that we would like to evenly distribute the data across the classes.\n",
    "To do this, we can use the following approach:\n",
    "\n",
    "1. Set a minimum of 100 samples per class for the training set and 25 for the validation set.\n",
    "2. For classes with less than 125 total samples, put all in training.\n",
    "3. For classes with 125-3125 samples, use an 80-20 split.\n",
    "4. For classes with over 3125 samples (outliers), cap the training at 1700 and validation at 400.\n",
    "\n",
    "\n",
    "This approach would:\n",
    "1. Ensure all classes are represented in both sets.\n",
    "2. Prevent rare classes from being excluded.\n",
    "3. Limit the influence of extremely common classes.\n",
    "4. Maintain a reasonable overall train-validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lib.easy_vqa.easyvqa_base:Read combined dataset, length: 48248\n",
      "Map: 100%|██████████| 13558/13558 [00:01<00:00, 13223.11 examples/s]\n",
      "Casting to class labels: 100%|██████████| 13558/13558 [00:00<00:00, 317095.79 examples/s]\n",
      "INFO:lib.easy_vqa.easyvqa_base:Read train dataset, length: 10846\n",
      "INFO:lib.dataset_base:Preparing data for training\n",
      "Map: 100%|██████████| 10846/10846 [00:00<00:00, 12497.93 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of items:\n",
      " 10846\n",
      "Top 10 most frequent labels:\n",
      "            Frequency\n",
      "rectangle       1370\n",
      "no              1360\n",
      "yes             1351\n",
      "circle          1347\n",
      "triangle        1287\n",
      "teal             532\n",
      "green            530\n",
      "yellow           526\n",
      "gray             524\n",
      "black            521\n",
      "Top 10 least frequent labels:\n",
      "           Frequency\n",
      "circle         1347\n",
      "triangle       1287\n",
      "teal            532\n",
      "green           530\n",
      "yellow          526\n",
      "gray            524\n",
      "black           521\n",
      "blue            520\n",
      "red             492\n",
      "brown           486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lib.easy_vqa.easyvqa_base:Read combined dataset, length: 48248\n",
      "INFO:lib.easy_vqa.easyvqa_base:Read val dataset, length: 3347\n",
      "INFO:lib.dataset_base:Preparing data for training\n",
      "Map: 100%|██████████| 3347/3347 [00:00<00:00, 12735.26 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of items:\n",
      " 3347\n",
      "Top 10 most frequent labels:\n",
      "            Frequency\n",
      "rectangle        431\n",
      "circle           421\n",
      "triangle         401\n",
      "no               400\n",
      "yes              400\n",
      "teal             169\n",
      "green            166\n",
      "gray             165\n",
      "black            164\n",
      "blue             163\n",
      "Top 10 least frequent labels:\n",
      "         Frequency\n",
      "no            400\n",
      "yes           400\n",
      "teal          169\n",
      "green         166\n",
      "gray          165\n",
      "black         164\n",
      "blue          163\n",
      "yellow        162\n",
      "red           153\n",
      "brown         152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lib.easy_vqa.easyvqa_base:Read combined dataset, length: 48248\n",
      "Map: 100%|██████████| 13558/13558 [00:01<00:00, 12871.19 examples/s]\n",
      "Casting to class labels: 100%|██████████| 13558/13558 [00:00<00:00, 305920.69 examples/s]\n",
      "INFO:lib.easy_vqa.easyvqa_base:Read test dataset, length: 2712\n",
      "INFO:lib.dataset_base:Preparing data for training\n",
      "Map: 100%|██████████| 2712/2712 [00:00<00:00, 12256.04 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of items:\n",
      " 2712\n",
      "Top 10 most frequent labels:\n",
      "            Frequency\n",
      "no               340\n",
      "yes              338\n",
      "circle           337\n",
      "rectangle        326\n",
      "triangle         323\n",
      "red              140\n",
      "gray             137\n",
      "blue             135\n",
      "teal             132\n",
      "brown            132\n",
      "Top 10 least frequent labels:\n",
      "            Frequency\n",
      "rectangle        326\n",
      "triangle         323\n",
      "red              140\n",
      "gray             137\n",
      "blue             135\n",
      "teal             132\n",
      "brown            132\n",
      "yellow           131\n",
      "green            126\n",
      "black            115\n"
     ]
    }
   ],
   "source": [
    "args = VQAParameters(\"train\", recompute=True, use_proportional_split=True)\n",
    "args.processor = processor\n",
    "dataset_train = EasyVQAGeneration(args)\n",
    "calculate_label_frequency(dataset_train, path=f\"{EASY_VQA_FILTERED}_train\")\n",
    "\n",
    "args = VQAParameters(\"val\", recompute=True, use_proportional_split=True)\n",
    "args.processor = processor\n",
    "dataset_val = EasyVQAGeneration(args)\n",
    "calculate_label_frequency(dataset_val, path=f\"{EASY_VQA_FILTERED}_val\")\n",
    "\n",
    "\n",
    "args = VQAParameters(\"test\", recompute=True, use_proportional_split=True)\n",
    "args.processor = processor\n",
    "dataset_test = EasyVQAGeneration(args)\n",
    "calculate_label_frequency(dataset_test, path=f\"{EASY_VQA_FILTERED}_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: 521.0\n",
      "Q2: 530.0\n",
      "Q3: 1347.0\n",
      "IQR: 826.0\n",
      "Lower Whisker: -718.0\n",
      "Upper Whisker: 2586.0\n",
      "Number of unique labels: 13\n",
      "Mean frequency: 834.31\n",
      "Median frequency: 530.00\n",
      "Number of outliers: 0\n",
      "Total number of items: 10846\n",
      "Q1: 163.0\n",
      "Q2: 166.0\n",
      "Q3: 400.0\n",
      "IQR: 237.0\n",
      "Lower Whisker: -192.5\n",
      "Upper Whisker: 755.5\n",
      "Number of unique labels: 13\n",
      "Mean frequency: 257.46\n",
      "Median frequency: 166.00\n",
      "Number of outliers: 0\n",
      "Total number of items: 3347\n"
     ]
    }
   ],
   "source": [
    "create_label_frequency_boxplot(dataset_train, path=f\"{EASY_VQA_FILTERED}_train\")\n",
    "create_label_frequency_boxplot(dataset_val, path=f\"{EASY_VQA_FILTERED}_val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined DAQUAM dataset\n",
    "## Combined dataset analysis\n",
    "### Box Plots\n",
    "\n",
    "Intuition around the boxplot:\n",
    "1. The dataset is highly unbalanced, with many classes having only a few samples.\n",
    "2. The boxplot shows that most of the labels are clustered near the lower end of the distribution, with a few classes having a large number of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: 2.0\n",
      "Q2: 4.0\n",
      "Q3: 13.75\n",
      "IQR: 11.75\n",
      "Lower Whisker: -15.625\n",
      "Upper Whisker: 31.375\n",
      "Number of unique labels: 582\n",
      "Mean frequency: 24.62\n",
      "Median frequency: 4.00\n",
      "Number of outliers: 92\n",
      "Total number of items: 12468\n"
     ]
    }
   ],
   "source": [
    "args = VQAParameters(Suffix.All, recompute=True) # using combined dataset\n",
    "args.processor = processor\n",
    "dataset = DaquarGeneration(args)\n",
    "create_label_frequency_boxplot(dataset, path=f\"{DAQUAR_COMBINED}_all\", multilabel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of items:\n",
      " 12468\n",
      "Top 10 most frequent labels:\n",
      "          Frequency\n",
      "2              554\n",
      "table          469\n",
      "chair          412\n",
      "lamp           351\n",
      "white          349\n",
      "photo          341\n",
      "3              327\n",
      "picture        308\n",
      "window         284\n",
      "books          281\n",
      "Top 10 least frequent labels:\n",
      "                  Frequency\n",
      "dish_rack                1\n",
      "dog_cage                 1\n",
      "file_stand               1\n",
      "binder                   1\n",
      "chest                    1\n",
      "soap_holder              1\n",
      "iron_grill               1\n",
      "cat_cage                 1\n",
      "staple_remover           1\n",
      "indoor_fountain          1\n"
     ]
    }
   ],
   "source": [
    "calculate_label_frequency(dataset, path=f\"{DAQUAR_COMBINED}_all\", multilabel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtered Data\n",
    "### Box Plots\n",
    "\n",
    "The problem is handled in the following way:\n",
    "1. **Combine the training and validation sets.** In order to have a general understanding of the amount of data per label available.\n",
    "1. **Remove infrequent labels.** Remove all labels with less than 50 training examples, since they cause can cause a of noise during training.\n",
    "2. **Do not remove upper-end outliers.** Since the task is relatively difficult, we'd like to keep as much data as possible, even the outliers at the upper-end of the distribution.\n",
    "3. **Stratify the split.** We use an 80-20 stratified split to ensure that the training and validation sets are representative of the original dataset.\n",
    "4. **Class specific weighting.** We use class weights to address the issue of class imbalance during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lib.dataset_base:Loaded 9523 items from /home/atomwalk12/Dropbox (Old)/notes/vision/project/BeyondVisionQA/VisualQA/data/daquar/generation/all.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: 73.75\n",
      "Q2: 104.5\n",
      "Q3: 205.0\n",
      "IQR: 131.25\n",
      "Lower Whisker: -123.125\n",
      "Upper Whisker: 401.875\n",
      "Number of unique labels: 68\n",
      "Mean frequency: 154.62\n",
      "Median frequency: 104.50\n",
      "Number of outliers: 3\n",
      "Total number of items: 9523\n"
     ]
    }
   ],
   "source": [
    "args = VQAParameters(Suffix.All, use_filtered_split=True) # using combined dataset\n",
    "args.processor = processor\n",
    "filtered_dataset = DaquarGeneration(args)\n",
    "create_label_frequency_boxplot(filtered_dataset, path=f\"{DAQUAR_FILTERED}_filtered\", multilabel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of items:\n",
      " 9523\n",
      "Top 10 most frequent labels:\n",
      "          Frequency\n",
      "2              554\n",
      "table          469\n",
      "chair          412\n",
      "lamp           351\n",
      "white          349\n",
      "photo          341\n",
      "3              327\n",
      "picture        308\n",
      "window         284\n",
      "books          281\n",
      "Top 10 least frequent labels:\n",
      "                             Frequency\n",
      "light                              64\n",
      "bowl                               60\n",
      "basket                             58\n",
      "stove                              57\n",
      "night_stand                        56\n",
      "gray                               56\n",
      "toilet                             53\n",
      "bottle_of_hand_wash_liquid         52\n",
      "ornamental_plant                   50\n",
      "plant                              50\n"
     ]
    }
   ],
   "source": [
    "calculate_label_frequency(filtered_dataset, path=f\"{DAQUAR_FILTERED}_filtered\", multilabel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing results\n",
    "### Outliers\n",
    "**Capping.** It is likely not a good idea to cap the number of examples per class, as this can lead to the loss of important data and information. Instead, we can use stratified sampling to ensure that each class is represented in the training and validation sets.\n",
    "\n",
    "\n",
    "**Stratified Sampling.** Instead of capping number of examples per class, we can instead use stratified sampling to ensure that each class is represented in the training and validation sets.\n",
    "\n",
    "**Class Weighting.** Moreover, by using class weights, we can ensure that class imbalances are addressed during the actual training process. This assures that the model pays more attention to the rare classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lib.dataset_base:Loaded 7604 items from /home/atomwalk12/Dropbox (Old)/notes/vision/project/BeyondVisionQA/VisualQA/data/daquar/generation/train.pkl\n",
      "INFO:lib.dataset_base:Loaded 1919 items from /home/atomwalk12/Dropbox (Old)/notes/vision/project/BeyondVisionQA/VisualQA/data/daquar/generation/val.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: 58.75\n",
      "Q2: 83.5\n",
      "Q3: 164.0\n",
      "IQR: 105.25\n",
      "Lower Whisker: -99.125\n",
      "Upper Whisker: 321.875\n",
      "Number of unique labels: 68\n",
      "Mean frequency: 123.72\n",
      "Median frequency: 83.50\n",
      "Number of outliers: 3\n",
      "Total number of items: 7604\n",
      "Q1: 15.0\n",
      "Q2: 21.0\n",
      "Q3: 41.0\n",
      "IQR: 26.0\n",
      "Lower Whisker: -24.0\n",
      "Upper Whisker: 80.0\n",
      "Number of unique labels: 68\n",
      "Mean frequency: 30.90\n",
      "Median frequency: 21.00\n",
      "Number of outliers: 3\n",
      "Total number of items: 1919\n"
     ]
    }
   ],
   "source": [
    "args = VQAParameters(Suffix.Train, use_proportional_split=True) # using combined dataset\n",
    "args.processor = processor\n",
    "train_dataset = DaquarGeneration(args)\n",
    "create_label_frequency_boxplot(train_dataset, f\"{DAQUAR_PROPORTIONAL}_train\", multilabel=True)\n",
    "\n",
    "args = VQAParameters(Suffix.Val, use_proportional_split=True) # using combined dataset\n",
    "args.processor = processor\n",
    "val_dataset = DaquarGeneration(args)\n",
    "create_label_frequency_boxplot(val_dataset, f\"{DAQUAR_PROPORTIONAL}_val\", multilabel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cardinality and Density\n",
    "\n",
    "- A high label cardinality indicates that most instances are associated with multiple labels.\n",
    "- A low label density might suggest that not all labels are used frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique labels: 68\n",
      "Label Cardinality: 1.106391372961599\n",
      "Label Density: 0.01627046136708234\n",
      "Average number of labels per sample: 1.11\n",
      "The number of unique labels: 68\n",
      "Label Cardinality: 1.0948410630536738\n",
      "Label Density: 0.01610060386843638\n",
      "Average number of labels per sample: 1.09\n"
     ]
    }
   ],
   "source": [
    "calculate_cardinality_and_density(train_dataset)\n",
    "calculate_cardinality_and_density(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of items:\n",
      " 7604\n",
      "Top 10 most frequent labels:\n",
      "          Frequency\n",
      "2              443\n",
      "table          375\n",
      "chair          330\n",
      "lamp           281\n",
      "white          279\n",
      "photo          273\n",
      "3              262\n",
      "picture        247\n",
      "window         227\n",
      "books          225\n",
      "Top 10 least frequent labels:\n",
      "                             Frequency\n",
      "light                              51\n",
      "bowl                               48\n",
      "stove                              46\n",
      "basket                             46\n",
      "gray                               45\n",
      "night_stand                        45\n",
      "toilet                             42\n",
      "bottle_of_hand_wash_liquid         42\n",
      "plant                              40\n",
      "ornamental_plant                   40\n",
      "Total number of items:\n",
      " 1919\n",
      "Top 10 most frequent labels:\n",
      "          Frequency\n",
      "2              111\n",
      "table           94\n",
      "chair           82\n",
      "white           70\n",
      "lamp            70\n",
      "photo           68\n",
      "3               65\n",
      "picture         61\n",
      "window          57\n",
      "books           56\n",
      "Top 10 least frequent labels:\n",
      "                             Frequency\n",
      "papers                             13\n",
      "bowl                               12\n",
      "basket                             12\n",
      "toilet                             11\n",
      "night_stand                        11\n",
      "stove                              11\n",
      "gray                               11\n",
      "plant                              10\n",
      "ornamental_plant                   10\n",
      "bottle_of_hand_wash_liquid         10\n"
     ]
    }
   ],
   "source": [
    "label_frequency_train = calculate_label_frequency(train_dataset, path=f\"{DAQUAR_PROPORTIONAL}_train\", multilabel=True)\n",
    "label_frequency_val = calculate_label_frequency(val_dataset, path=f\"{DAQUAR_PROPORTIONAL}_val\", multilabel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lib.easy_vqa.easyvqa_base:Read combined dataset, length: 48248\n",
      "INFO:lib.dataset_base:Preparing data for training\n",
      "Map: 100%|██████████| 48248/48248 [00:02<00:00, 17051.95 examples/s]\n",
      "/home/atomwalk12/anaconda3/envs/dev/lib/python3.12/site-packages/torch/storage.py:414: FutureWarning:\n",
      "\n",
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\n",
      "/home/atomwalk12/anaconda3/envs/dev/lib/python3.12/site-packages/umap/umap_.py:1945: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lib.models.feature_visualizer import FeatureVisualizer\n",
    "import pickle\n",
    "\n",
    "args = VQAParameters(Suffix.Train, recompute=True) # using combined dataset\n",
    "args.processor = processor\n",
    "dataset = EasyVQAGeneration(args)\n",
    "\n",
    "split = \"train\"\n",
    "#path = f\"data/models/easy_vqa/classifier/2088502146/features_{split}.pkl\" represent the raw features not classifier outputs\n",
    "path = f\"data/models/easy_vqa/classifier/710142242/features_{split}.pkl\" # classifier outputs\n",
    "data = pickle.load(open(path, \"rb\"))\n",
    "features = data[\"features\"]\n",
    "labels = data[\"labels\"]\n",
    "\n",
    "feature_visualizer = FeatureVisualizer(id_to_answer=dataset.id_to_answer, dataset_name=\"easy_vqa\")\n",
    "feature_visualizer.set_features(features, labels, split)\n",
    "feature_visualizer.visualize_features_with_umap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lib.dataset_base:Preparing data for training\n",
      "Map: 100%|██████████| 12468/12468 [00:00<00:00, 18921.54 examples/s]\n",
      "/home/atomwalk12/anaconda3/envs/dev/lib/python3.12/site-packages/torch/storage.py:414: FutureWarning:\n",
      "\n",
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\n",
      "/home/atomwalk12/anaconda3/envs/dev/lib/python3.12/site-packages/umap/umap_.py:1945: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from lib.models.feature_visualizer import FeatureVisualizer\n",
    "import pickle\n",
    "\n",
    "args = VQAParameters(Suffix.Train, recompute=True) # using combined dataset\n",
    "args.processor = processor\n",
    "dataset = DaquarGeneration(args)\n",
    "\n",
    "split = \"train\"\n",
    "#path = f\"data/models/easy_vqa/classifier/2088502146/features_{split}.pkl\" represent the raw features not classifier outputs\n",
    "path = f\"data/models/daquar/classifier/452947361/features_{split}.pkl\" # classifier outputs\n",
    "data = pickle.load(open(path, \"rb\"))\n",
    "features = data[\"features\"]\n",
    "labels = data[\"labels\"]\n",
    "\n",
    "feature_visualizer = FeatureVisualizer(id_to_answer=dataset.id_to_answer, dataset_name=\"daquar\")\n",
    "feature_visualizer.set_features(features, labels, split)\n",
    "feature_visualizer.visualize_features_with_umap()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
